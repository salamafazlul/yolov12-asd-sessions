{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Session 1**"
      ],
      "metadata": {
        "id": "BaWyscBxVc-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GzRxoe1sAj27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc97d97-d550-4c99-a643-fd9b20522339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 18 21:33:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzlqzVRTN4zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824139d4-bf41-4d98-e438-e5959881386e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint Directory\n",
        "import os\n",
        "DRIVE_CHECKPOINT_DIR = '/content/drive/MyDrive/YOLOv12_ASD_Checkpoints'\n",
        "if not os.path.exists(DRIVE_CHECKPOINT_DIR):\n",
        "    raise FileNotFoundError(\"Make sure the shortcut 'YOLOv12_ASD_Checkpoints' is in your MyDrive.\")\n",
        "os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "ovOIGVNJOL-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment flag\n",
        "os.environ[\"NO_ALBUMENTATIONS_UPDATE\"] = \"1\""
      ],
      "metadata": {
        "id": "hZHvpp5mg1dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/sunsmarterjie/yolov12.git roboflow supervision flash-attn albumentations comet_ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQA_HB84Z5wj",
        "outputId": "7872613d-ecfd-4ae6-d336-da2569dc5b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports after dependencies\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from google.colab import userdata\n",
        "import comet_ml\n",
        "from roboflow import Roboflow\n",
        "import time\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4MjkFFskPu9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b69850-21c3-443e-cd22-cb7c0ca26978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/yolov12/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "FlashAttention is not available on this device. Using scaled_dot_product_attention instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify shared folder access\n",
        "print(f\"Using shared folder: {DRIVE_CHECKPOINT_DIR}\")\n",
        "!ls {DRIVE_CHECKPOINT_DIR}"
      ],
      "metadata": {
        "id": "UXbyTxwxQdOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac8eeb6-de47-4f6c-f056-279913ca41f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using shared folder: /content/drive/MyDrive/YOLOv12_ASD_Checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "m5_svDjCQlhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variables\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "os.environ[\"COMET_API_KEY\"] = userdata.get(\"COMET_API_KEY\")"
      ],
      "metadata": {
        "id": "bbgmMFJTf0Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Roboflow\n",
        "rf = Roboflow(api_key=os.environ[\"ROBOFLOW_API_KEY\"])\n",
        "project = rf.workspace(\"noor-fatima-vfkuh\").project(\"asd-eobeu\")\n",
        "dataset = project.version(18).download(\"yolov8\")\n",
        "dataset_location = dataset.location"
      ],
      "metadata": {
        "id": "Nuiz10buf16Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e707d59d-584b-4bb4-f973-8624c13d62bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in ASD-18 to yolov8:: 100%|██████████| 493384/493384 [00:13<00:00, 35812.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ASD-18 in yolov8:: 100%|██████████| 26274/26274 [00:03<00:00, 6730.46it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify dataset structure\n",
        "print(\"Verifying dataset structure:\")\n",
        "!ls {dataset_location}\n",
        "for folder in ['train', 'valid', 'test']:\n",
        "    if os.path.exists(os.path.join(dataset_location, folder, 'images')):\n",
        "        print(f\"{folder}/images found\")\n",
        "    else:\n",
        "        print(f\"Warning: {folder}/images not found\")"
      ],
      "metadata": {
        "id": "0f4u2avhgADv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc619747-8095-432a-dea7-e44ca0139711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying dataset structure:\n",
            "data.yaml  README.dataset.txt  README.roboflow.txt  test  train  valid\n",
            "train/images found\n",
            "valid/images found\n",
            "test/images found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update data.yaml\n",
        "data_yaml_path = f\"{dataset_location}/data.yaml\"\n",
        "try:\n",
        "    with open(data_yaml_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    lines = [line for line in lines if not line.startswith(('test:', 'train:', 'val:'))]\n",
        "    lines.extend([\n",
        "        \"test: ./test/images\\n\",\n",
        "        \"train: ./train/images\\n\",\n",
        "        \"val: ./valid/images\\n\"\n",
        "    ])\n",
        "    with open(data_yaml_path, 'w') as file:\n",
        "        file.writelines(lines)\n",
        "    print(\"data.yaml updated successfully\")\n",
        "    with open(data_yaml_path, 'r') as file:\n",
        "        print(\"data.yaml contents:\")\n",
        "        print(file.read())\n",
        "except Exception as e:\n",
        "    print(f\"Error updating data.yaml: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "RjNy4Sk6gEnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a426e3-5983-475e-f912-fdd65269696f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml updated successfully\n",
            "data.yaml contents:\n",
            "names:\n",
            "- Lack_social_skill\n",
            "- Stimming\n",
            "- aligning_objects\n",
            "- avoid_eye_contact\n",
            "- awkward_posture\n",
            "- clapping\n",
            "- closing_eyes\n",
            "- continuous_moving\n",
            "- exaggerated_expression\n",
            "- face_rubbing\n",
            "- finger_biting\n",
            "- finger_flapping\n",
            "- finger_smelling\n",
            "- finger_tapping\n",
            "- hand_flapping\n",
            "- hand_leading\n",
            "- head_banging\n",
            "- holding_objects\n",
            "- jumping\n",
            "- lack_of_awareness\n",
            "- lack_of_response\n",
            "- moving_hand_upforth\n",
            "- normal\n",
            "- repetitive_action\n",
            "- rocking\n",
            "- rubbing_eyes\n",
            "- rubbing_hands\n",
            "- rubbing_nose\n",
            "- rubbing_objects\n",
            "- smelling\n",
            "- spinning\n",
            "- tapping_head\n",
            "- weird_expression\n",
            "- weird_laugh\n",
            "nc: 34\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: asd-eobeu\n",
            "  url: https://universe.roboflow.com/noor-fatima-vfkuh/asd-eobeu/dataset/18\n",
            "  version: 18\n",
            "  workspace: noor-fatima-vfkuh\n",
            "test: ./test/images\n",
            "train: ./train/images\n",
            "val: ./valid/images\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply augmentations\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.3),\n",
        "    A.RandomBrightnessContrast(p=0.4, brightness_limit=0.2, contrast_limit=0.2),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.Resize(640, 640),\n",
        "])\n",
        "\n",
        "def apply_augmentation_to_folder(img_folder):\n",
        "    for file in tqdm(os.listdir(img_folder), desc=\"Augmenting images\"):\n",
        "        path = os.path.join(img_folder, file)\n",
        "        try:\n",
        "            img = cv2.imread(path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            augmented = transform(image=img)['image']\n",
        "            cv2.imwrite(path, augmented)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "apply_augmentation_to_folder(f\"{dataset_location}/train/images\")"
      ],
      "metadata": {
        "id": "1NIIX2O-gLP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430ff204-4c6d-437b-f21e-614c5b406c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting images: 100%|██████████| 11672/11672 [01:08<00:00, 169.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to log metrics to Comet ML\n",
        "def log_metrics_to_comet(experiment, session_number, results_csv_path):\n",
        "    try:\n",
        "        if not os.path.exists(results_csv_path):\n",
        "            experiment.log_text(f\"Results CSV not found at {results_csv_path} for session {session_number}\")\n",
        "            return\n",
        "        results_df = pd.read_csv(results_csv_path)\n",
        "        results_df.columns = results_df.columns.str.strip()\n",
        "        global_epoch_offset = (session_number - 1) * 10\n",
        "        for i, row in results_df.iterrows():\n",
        "            metrics = {\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]) if not pd.isna(row[\"train/box_loss\"]) else 0.0,\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]) if not pd.isna(row[\"train/cls_loss\"]) else 0.0,\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]) if not pd.isna(row[\"train/dfl_loss\"]) else 0.0,\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]) if not pd.isna(row[\"val/box_loss\"]) else 0.0,\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]) if not pd.isna(row[\"val/cls_loss\"]) else 0.0,\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]) if not pd.isna(row[\"val/dfl_loss\"]) else 0.0,\n",
        "                \"metrics/precision(B)\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"metrics/recall(B)\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"metrics/mAP50(B)\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"metrics/mAP50-95(B)\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "                \"lr/pg0\": float(row[\"lr/pg0\"]),\n",
        "                \"lr/pg1\": float(row[\"lr/pg1\"]),\n",
        "                \"lr/pg2\": float(row[\"lr/pg2\"])\n",
        "            }\n",
        "            experiment.log_metrics(metrics, step=global_epoch_offset + i + 1)\n",
        "        print(f\"Metrics logged to Comet ML for session {session_number}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error logging metrics from results.csv: {e}\")\n",
        "        experiment.log_text(f\"Error logging metrics for session {session_number}: {str(e)}\")"
      ],
      "metadata": {
        "id": "F61tF0FE9G_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Comet ML\n",
        "try:\n",
        "    comet_ml.login(api_key=userdata.get(\"COMET_API_KEY\"))\n",
        "except Exception as e:\n",
        "    print(f\"Error logging into Comet ML: {e}\")\n",
        "    raise\n",
        "\n",
        "session_number = 1  # Session 1"
      ],
      "metadata": {
        "id": "YhXT6POKgNgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef46485-183d-4fa1-ca5f-777707da19d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /content/drive/MyDrive/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Securely validate API keys\n",
        "try:\n",
        "    if not userdata.get(\"COMET_API_KEY\"):\n",
        "        raise ValueError(\"COMET_API_KEY not set in Colab Secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error validating COMET_API_KEY: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "7z71wnAf9ZK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new experiment\n",
        "try:\n",
        "    experiment = comet_ml.Experiment(\n",
        "        project_name=\"yolov12-autism-detection\",\n",
        "        workspace=\"salamafazlul\"\n",
        "    )\n",
        "    with open(os.path.join(DRIVE_CHECKPOINT_DIR, 'experiment_id.txt'), 'w') as f:\n",
        "        f.write(experiment.id)\n",
        "    experiment.log_text(f\"Experiment ID: {experiment.id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating Comet ML experiment: {e}\")\n",
        "    raise\n",
        "\n",
        "try:\n",
        "    experiment.set_name(\"asd_yolov12_100_epochs\")\n",
        "    experiment.log_parameters({\n",
        "        \"epochs\": 10,\n",
        "        \"total_epochs\": 100,\n",
        "        \"imgsz\": 640,\n",
        "        \"batch\": 8,\n",
        "        \"device\": 0,\n",
        "        \"model\": \"yolov12m.yaml\",\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"lr0\": 0.0001,  # Reduced to avoid nan\n",
        "        \"session_number\": session_number\n",
        "    })\n",
        "except Exception as e:\n",
        "    print(f\"Error setting Comet ML parameters: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "FLyNmXWdh4iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eac7b16-fd08-4838-81bd-c50fd47a97b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/salamafazlul/yolov12-autism-detection/9976311611eb4d3b9b455d35577e2a52\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "try:\n",
        "    print(f\"Starting new training session {session_number}\")\n",
        "    model = YOLO(\"yolov12m.yaml\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing model: {e}\")\n",
        "    experiment.log_text(f\"Error initializing model: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "Kesr91PHiP5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1607d1f4-f379-4718-ee63-d0060665bce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting new training session 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "start_time = time.time()\n",
        "try:\n",
        "    model.train(\n",
        "        data=data_yaml_path,\n",
        "        epochs=10,\n",
        "        imgsz=640,\n",
        "        batch=8,\n",
        "        device=0,\n",
        "        amp=True,\n",
        "        cache=False,\n",
        "        save_period=4,\n",
        "        name=f\"asd_yolov12_session_{session_number}\",\n",
        "        project=\"autism-detection\",\n",
        "        exist_ok=True,\n",
        "        verbose=True,\n",
        "        patience=10,\n",
        "        optimizer=\"AdamW\",\n",
        "        lr0=0.0001,  # Reduced\n",
        "        cos_lr=True\n",
        "    )\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Training interrupted, logging metrics and saving checkpoint...\")\n",
        "    try:\n",
        "        results_csv_path = f\"autism-detection/asd_yolov12_session_{session_number}/results.csv\"\n",
        "        log_metrics_to_comet(experiment, session_number, results_csv_path)\n",
        "        model.save(os.path.join(DRIVE_CHECKPOINT_DIR, \"last.pt\"))\n",
        "        experiment.log_model(\"yolov12_asd_last\", os.path.join(DRIVE_CHECKPOINT_DIR, \"last.pt\"))\n",
        "        experiment.end()\n",
        "        print(\"Checkpoint saved to Google Drive\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during interrupt handling: {e}\")\n",
        "        experiment.log_text(f\"Error during interrupt for session {session_number}: {str(e)}\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"Training error: {e}\")\n",
        "    experiment.log_text(f\"Training error for session {session_number}: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "print(f\"Session {session_number} took {(time.time() - start_time) / 60:.2f} minutes\")"
      ],
      "metadata": {
        "id": "EQP9GJxgjP8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c782759-5beb-4bed-a528-35ceef844694"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.139 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov12m.yaml, data=/content/ASD-18/data.yaml, epochs=10, time=None, patience=10, batch=8, imgsz=640, save=True, save_period=4, cache=False, device=0, workers=8, project=autism-detection, name=asd_yolov12_session_1, exist_ok=True, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.1, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=autism-detection/asd_yolov12_session_1\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/yolov12/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 25.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=34\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     37120  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2, 1, 2]         \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    147968  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2, 1, 4]        \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  2   2664960  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 4]        \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  2   2664960  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1   1248768  ultralytics.nn.modules.block.A2C2f           [1024, 512, 1, False, -1]     \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1    378624  ultralytics.nn.modules.block.A2C2f           [1024, 256, 1, False, -1]     \n",
            " 15                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1   1183232  ultralytics.nn.modules.block.A2C2f           [768, 512, 1, False, -1]      \n",
            " 18                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 21        [14, 17, 20]  1   1437238  ultralytics.nn.modules.head.Detect           [34, [256, 512, 512]]         \n",
            "YOLOv12m summary: 533 layers, 19,635,318 parameters, 19,635,302 gradients, 60.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir autism-detection/asd_yolov12_session_1', view at http://localhost:6006/\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/sunsmarterjie/yolov12/releases/download/turbo/yolov12n.pt to 'yolov12n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.26M/5.26M [00:00<00:00, 97.9MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/ASD-18/train/labels... 11672 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11672/11672 [00:06<00:00, 1918.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/ASD-18/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ASD-18/valid/labels... 730 images, 0 backgrounds, 0 corrupt: 100%|██████████| 730/730 [00:01<00:00, 704.56it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/ASD-18/valid/images/Screenshot-2024-08-26-111148_jpg.rf.02242ccd47e086b3277d53a649f9c502.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/ASD-18/valid/images/Screenshot-2024-08-26-111148_jpg.rf.6ff0fd368a89c33f50c454bb6868b5ff.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/ASD-18/valid/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to autism-detection/asd_yolov12_session_1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 131 weight(decay=0.0), 138 weight(decay=0.0005), 137 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mautism-detection/asd_yolov12_session_1\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Argument(s) 'quality_lower' are not valid for transform ImageCompression\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10      6.61G      2.815      5.829      4.162          8        640: 100%|██████████| 1459/1459 [12:04<00:00,  2.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.89it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743      0.797    0.00196    0.00123   0.000231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10      6.61G      2.528      5.085      3.531          8        640: 100%|██████████| 1459/1459 [11:51<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.96it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743    0.00334      0.532     0.0148    0.00485\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10      6.49G      2.174       4.37      2.956          8        640: 100%|██████████| 1459/1459 [11:45<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.98it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743        0.9      0.018     0.0327    0.00989\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10      6.49G      2.058      4.111      2.789          8        640: 100%|██████████| 1459/1459 [11:43<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.95it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743      0.918     0.0208      0.054     0.0193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10      6.61G      1.996      3.962      2.708          9        640: 100%|██████████| 1459/1459 [11:45<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.97it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743      0.722     0.0797     0.0783     0.0327\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10      6.48G      1.964      3.869      2.658          8        640: 100%|██████████| 1459/1459 [11:42<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.99it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        730        743      0.678     0.0838      0.107     0.0468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      6.48G      1.936      3.806      2.633          8        640: 100%|██████████| 1459/1459 [11:43<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        730        743      0.618      0.109      0.118     0.0502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      6.48G      1.916      3.746      2.611          8        640: 100%|██████████| 1459/1459 [11:43<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        730        743      0.589      0.115      0.144     0.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      6.49G      1.895      3.713      2.589          8        640: 100%|██████████| 1459/1459 [11:44<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        730        743      0.594      0.126       0.15     0.0656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      6.48G      1.879      3.689      2.578          8        640: 100%|██████████| 1459/1459 [11:45<00:00,  2.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:15<00:00,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        730        743      0.605       0.13      0.157     0.0718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 2.015 hours.\n",
            "Optimizer stripped from autism-detection/asd_yolov12_session_1/weights/last.pt, 39.8MB\n",
            "Optimizer stripped from autism-detection/asd_yolov12_session_1/weights/best.pt, 39.8MB\n",
            "\n",
            "Validating autism-detection/asd_yolov12_session_1/weights/best.pt...\n",
            "Ultralytics 8.3.63 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv12m summary (fused): 402 layers, 19,602,742 parameters, 0 gradients, 59.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 46/46 [00:16<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        730        743      0.606       0.13      0.157     0.0716\n",
            "     Lack_social_skill         18         18          1          0     0.0131    0.00458\n",
            "              Stimming         17         17     0.0471      0.765      0.399      0.178\n",
            "      aligning_objects         16         16          1          0      0.416       0.22\n",
            "     avoid_eye_contact         21         21      0.147       0.19      0.173     0.0381\n",
            "       awkward_posture         21         21      0.392     0.0926     0.0762     0.0504\n",
            "              clapping          8          8          1          0      0.138     0.0771\n",
            "          closing_eyes         13         13          1          0     0.0348      0.024\n",
            "     continuous_moving         15         15          1          0     0.0706     0.0289\n",
            "exaggerated_expression         17         17          1          0      0.024     0.0121\n",
            "          face_rubbing         16         16      0.199      0.375      0.277      0.143\n",
            "         finger_biting         23         23      0.121      0.174      0.194      0.104\n",
            "       finger_flapping         22         22          1          0     0.0445     0.0168\n",
            "       finger_smelling         15         15          1          0    0.00706    0.00279\n",
            "        finger_tapping         56         56          1          0    0.00536    0.00202\n",
            "         hand_flapping         26         26     0.0882      0.115     0.0678     0.0241\n",
            "          hand_leading         16         16          1          0      0.104     0.0419\n",
            "          head_banging         13         13     0.0805      0.538      0.461      0.171\n",
            "       holding_objects         19         24          0          0     0.0573     0.0291\n",
            "               jumping         20         20          1          0     0.0107    0.00391\n",
            "     lack_of_awareness         17         17          1          0     0.0154    0.00668\n",
            "      lack_of_response          9         10          1          0     0.0208    0.00592\n",
            "   moving_hand_upforth         11         11      0.241      0.182      0.131      0.087\n",
            "                normal         25         25       0.13       0.28      0.225      0.109\n",
            "     repetitive_action         26         26          1          0     0.0537     0.0173\n",
            "               rocking         19         20      0.238        0.9      0.846      0.401\n",
            "          rubbing_eyes          3          3          1          0    0.00666    0.00133\n",
            "         rubbing_hands          7          7          1          0       0.28      0.158\n",
            "          rubbing_nose         22         22          1          0    0.00961     0.0018\n",
            "       rubbing_objects          6          6          1          0      0.133     0.0598\n",
            "              smelling         19         19      0.197      0.368       0.25      0.127\n",
            "              spinning         75         75          0          0      0.166      0.042\n",
            "          tapping_head         93         93      0.614      0.359      0.553       0.21\n",
            "      weird_expression         18         18          0          0     0.0307     0.0146\n",
            "           weird_laugh         14         14     0.0998     0.0714     0.0455     0.0238\n",
            "Speed: 0.3ms preprocess, 16.5ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mautism-detection/asd_yolov12_session_1\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Couldn't retrieve and log Google Colab notebook content, reason: 'NoneType' object is not subscriptable\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : asd_yolov12_100_epochs\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/salamafazlul/yolov12-autism-detection/9976311611eb4d3b9b455d35577e2a52\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg0 [21]               : (3.4227024433898913e-06, 9.052565437184056e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg1 [21]               : (3.4227024433898913e-06, 9.052565437184056e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr/pg2 [21]               : (3.4227024433898913e-06, 9.052565437184056e-05)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50(B) [22]     : (0.00123, 0.15724)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/mAP50-95(B) [22]  : (0.00023, 0.07178)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/precision(B) [22] : (0.00334, 0.91792)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     metrics/recall(B) [22]    : (0.00196, 0.53155)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/GFLOPs              : 60.233\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/parameters          : 19635318\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model/speed_PyTorch(ms)   : 17.004\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/box_loss [20]       : (1.8787, 2.81475)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/cls_loss [20]       : (3.6891, 5.82898)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/dfl_loss [20]       : (2.57819, 4.16189)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/box_loss [20]         : (1.89214, 3.08404)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/cls_loss [20]         : (3.29012, 4.22528)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val/dfl_loss [20]         : (2.54279, 4.05856)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name         : asd_yolov12_100_epochs\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url : https://colab.research.google.com/notebook#fileId=14XAwBltjBQ4vS9J-h6NJLULPUUdFi1UA\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch          : 8\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     device         : 0\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epochs         : 10\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     imgsz          : 640\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     lr0            : 0.0001\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model          : yolov12m.yaml\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer      : AdamW\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     session_number : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_epochs   : 100\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     confusion-matrix    : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 17\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 3 (264.36 MB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 2 metrics, params and output messages\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session 1 took 121.83 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log metrics after training\n",
        "results_csv_path = f\"autism-detection/asd_yolov12_session_{session_number}/results.csv\"\n",
        "log_metrics_to_comet(experiment, session_number, results_csv_path)"
      ],
      "metadata": {
        "id": "O5Gz9Quk97zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87901e2-4d0e-4bc9-ec33-5a0179d0dbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics logged to Comet ML for session 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save final model for this session\n",
        "try:\n",
        "    model.save(os.path.join(DRIVE_CHECKPOINT_DIR, \"last.pt\"))\n",
        "    experiment.log_model(\"yolov12_asd_last\", os.path.join(DRIVE_CHECKPOINT_DIR, \"last.pt\"))\n",
        "    if os.path.exists(os.path.join(\"autism-detection\", f\"asd_yolov12_session_{session_number}\", \"weights\", \"best.pt\")):\n",
        "        shutil.copy(\n",
        "            os.path.join(\"autism-detection\", f\"asd_yolov12_session_{session_number}\", \"weights\", \"best.pt\"),\n",
        "            os.path.join(DRIVE_CHECKPOINT_DIR, \"best.pt\")\n",
        "        )\n",
        "        experiment.log_model(\"yolov12_asd_best\", os.path.join(DRIVE_CHECKPOINT_DIR, \"best.pt\"))\n",
        "except Exception as e:\n",
        "    print(f\"Error saving model: {e}\")\n",
        "    experiment.log_text(f\"Error saving model for session {session_number}: {str(e)}\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "uyMDRSrwjZfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# End Comet experiment\n",
        "try:\n",
        "    experiment.end()\n",
        "except Exception as e:\n",
        "    print(f\"Error ending Comet ML experiment: {e}\")\n",
        "    experiment.log_text(f\"Error ending experiment for session {session_number}: {str(e)}\")"
      ],
      "metadata": {
        "id": "9uTvtu2ejbL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}